{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Thanks to Daniel Villaveces' article on *Medium* for helping me to scrape the data from Citi Bike data. \n",
    "#### It saved me a lot of time that otherwise would have been spent downloading multiple zip files for each month.\n",
    "#### Daniel's article can be found [here](https://medium.com/@dvillaveces/analyzing-citi-bike-data-2202f9da97d7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scrape the citi bike index and extract the file names\n",
    "# the data begins in 2013, but I only want data from 2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the files also have a second file named with 'JC' for every month from 2015 - 2020 that seems to contain addtional/\n",
    "# trip data, so I will have to do this twice: first to get the 'non JC files' and then get the'JC' files\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['202001-citibike-tripdata.csv.zip',\n",
       " '202002-citibike-tripdata.csv.zip',\n",
       " '202003-citibike-tripdata.csv.zip',\n",
       " '202004-citibike-tripdata.csv.zip',\n",
       " '202005-citibike-tripdata.csv.zip',\n",
       " '202006-citibike-tripdata.csv.zip',\n",
       " '202007-citibike-tripdata.csv.zip',\n",
       " '202008-citibike-tripdata.csv.zip',\n",
       " '202009-citibike-tripdata.csv.zip',\n",
       " '202010-citibike-tripdata.csv.zip',\n",
       " '202011-citibike-tripdata.csv.zip',\n",
       " '202012-citibike-tripdata.csv.zip']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = 'https://s3.amazonaws.com/tripdata/'\n",
    "\n",
    "# load all url content into soup\n",
    "r = requests.get(url)\n",
    "soup = BeautifulSoup(r.text, 'xml')\n",
    "\n",
    "# extract file names from soup\n",
    "# data from 2020\n",
    "files = soup.find_all('Key')\n",
    "extract_files = []\n",
    "for i in range(80, 92):\n",
    "    extract_files.append(files[i].get_text())\n",
    "    \n",
    "extract_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['JC-202001-citibike-tripdata.csv.zip',\n",
       " 'JC-202002-citibike-tripdata.csv.zip',\n",
       " 'JC-202003-citibike-tripdata.csv.zip',\n",
       " 'JC-202004-citibike-tripdata.csv.zip',\n",
       " 'JC-202005-citibike-tripdata.csv.zip',\n",
       " 'JC-202006-citibike-tripdata.csv.zip',\n",
       " 'JC-202007-citibike-tripdata.csv.zip',\n",
       " 'JC-202008-citibike-tripdata.csv.zip',\n",
       " 'JC-202009-citibike-tripdata.csv.zip',\n",
       " 'JC-202010-citibike-tripdata.csv.zip',\n",
       " 'JC-202011-citibike-tripdata.csv.zip',\n",
       " 'JC-202012-citibike-tripdata.csv.zip']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extract the JC files, 2020\n",
    "files = soup.find_all('Key')\n",
    "jc_extract_files = []\n",
    "for i in range(145, len(files)-2):\n",
    "    jc_extract_files.append(files[i].get_text())\n",
    "    \n",
    "jc_extract_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
